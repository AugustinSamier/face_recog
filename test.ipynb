{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "065c9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb23f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(path,create_test=None):\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "\n",
    "    file=os.listdir(path)\n",
    "\n",
    "    for entity in file:\n",
    "        try:\n",
    "            entityPath=os.listdir(f\"{path}/{entity}\")\n",
    "            for i,data in enumerate(entityPath):\n",
    "                try:\n",
    "                    current_img=cv2.imread(f\"{path}/{entity}/{data}\")\n",
    "                    if current_img is not None:\n",
    "                        if (create_test is not None and ((len(entityPath)>1) and (i==0))):\n",
    "                            X_test.append(current_img)\n",
    "                            y_test.append(entity)\n",
    "                        else:\n",
    "                            X_train.append(current_img)\n",
    "                            y_train.append(entity)\n",
    "                    else:\n",
    "                        print(f\"{path}/{entity}/{data} is None type\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur avec {path}/{entity}/{data} : {e}\")\n",
    "        except Exception as ex:\n",
    "            print(f\"Erreur avec {path}/{entity} : {ex}\")\n",
    "    \n",
    "    if create_test is not None:\n",
    "        return X_train,y_train,X_test,y_test\n",
    "    else:\n",
    "        return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12b56c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgProcess(img,withTorch=None):\n",
    "    if not isinstance(img,np.ndarray):\n",
    "        print(\"convertion de l'img\")\n",
    "        img=cv2.imread(img)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #RGB -> Gray -> dim(255,255,3)=255*255*3 val de couleur = 195075 vals -> dim(255,255,1) -> 255*255*1 val de couleur = 65025 vals pour l'exemple du 255*255\n",
    "    img=cv2.resize(img,(100,100)) #dim -> dim(100,100,1) -> 100*100*1 = 10000 val de couleur\n",
    "    if withTorch is None:\n",
    "        img=img.flatten() #2D -> 1D vec de (10000,1)\n",
    "    else:\n",
    "        img=img.astype(np.float32)/255.0 #rescale entre 0 et 1\n",
    "        img=img[np.newaxis,:,:] #ajout d'une dimension pour la couleur\n",
    "        img=torch.tensor(img).unsqueeze(0) #ajout de la dimension de batch necessaire pour pytorch\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7cbfc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distEuclid(img1,img2): #p1(a1,a2,a3...,a10000) p2(b1,b2,b3...,b10000) car chaque image a 10000 val de couleur\n",
    "    #img1 = img1.astype(np.int32) #pour avoir des valeur négatives sinon en uint8 c'est de 0 à 255 (pas negatif)\n",
    "    #img2 = img2.astype(np.int32)\n",
    "    diff=img1.astype(np.int32)-img2.astype(np.int32) #opti\n",
    "\n",
    "    #distance euclidienne entre deux points (en 2D) p1(x1,y1) et p2(x2,y2): d=hypothénuse du triangle rectangle\n",
    "    #ainsi d²=a²+b² et d=sqrt(a²+b²) avec a=abs(x1-x2) et b=abs(y1-y2) DONC -> d=sqrt((x1-x2)²+(y1-y2)²)\n",
    "    #en n dim : d=sqrt((a1-b1)²+(a2-b2)²...+(an-bn)²) = sqrt(sum[1;N]((a-b)²))\n",
    "    #return sqrt(sum((a-b)**2 for a,b in zip(img1,img2))) #zip -> pour deux listes\n",
    "    return np.sqrt(np.sum(diff**2)) #opti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7dcc79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(X_train,y_train, newImg,k):\n",
    "    distances=[]\n",
    "    for i in range(len(X_train)):\n",
    "        dist=distEuclid(X_train[i],newImg) #on calcule la distance entre la nouvelle image et toutes les autres images\n",
    "        distances.append((dist,y_train[i])) #on stock la distance avec le label de chaque image à laquelle on a calculé la distance\n",
    "    \n",
    "    distances.sort(key=lambda x: x[0]) #on trie la liste de distances dans l'ordre croissant comme ça les derniers termes sont les plus proche de la nouvelle image\n",
    "    k_voisins=distances[:k] #on prend les k plus proches voisins\n",
    "\n",
    "    counts={} #dictionnaire pour compter les labels les plus proches et leur occurences\n",
    "    for _,label in k_voisins: #dans le tableau c'est [distance,label], ici on veut que le label donc _\n",
    "        counts[label]=counts.get(label,0)+1 #.get(a,b) = prend la val a si existe sinon prend la val b\n",
    "\n",
    "    return max(counts,key=counts.get) #compare les valeurs mais renvoie le label du dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6edd2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_evaluate(processed_train,y_train,processed_test,y_test,k,n):\n",
    "    knn_results=[]\n",
    "    true=0\n",
    "    if n is None:\n",
    "        n=len(processed_test)\n",
    "\n",
    "    print(f\"Number of sample set to : {n}\")\n",
    "    \n",
    "    for i,img in enumerate(processed_test[:n]):\n",
    "        print(f\"Image KNN : {i}\")\n",
    "        knn_results.append(knn_predict(processed_train,y_train,processed_test[i],k))\n",
    "        if knn_results[i]==y_test[i]:\n",
    "            true+=1\n",
    "    print(f\"Accuracy (%) : {100*true/n}\")\n",
    "\n",
    "    return knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a05402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train,y_train,X_test,y_test,k=3,n=None):\n",
    "    processed_train=[]\n",
    "    for img in X_train:\n",
    "        processed_train.append(imgProcess(img))\n",
    "\n",
    "    processed_test=[]\n",
    "    for img in X_test:\n",
    "        processed_test.append(imgProcess(img))\n",
    "    print(\"Processing done.\\n\")\n",
    "\n",
    "    knn_result=knn_evaluate(processed_train,y_train,processed_test,y_test,k,n)\n",
    "    return knn_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79fb2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgPadding(img,padding):\n",
    "    size=img.shape[0]\n",
    "    if padding is not None:\n",
    "        size=size+2*padding\n",
    "        newImg=np.zeros((size,size,3),dtype=np.uint8)\n",
    "        for x in range(padding,size-padding):\n",
    "            for y in range(padding,size-padding):\n",
    "                newImg[x][y]=img[x-padding][y-padding]\n",
    "    else:\n",
    "        newImg=img\n",
    "    return newImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4366c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(img,dim=2,padding=None,stride=1):\n",
    "    if padding is not None:\n",
    "        img=imgPadding(img,padding)\n",
    "    \n",
    "    newDim=((img.shape[0]-dim)//stride)+1\n",
    "    newImg=np.zeros([newDim,newDim,3])\n",
    "    \n",
    "    for rgb in range(img.shape[2]):\n",
    "        for x in range(0,(img.shape[0]//dim)*dim,stride):\n",
    "            for y in range(0,(img.shape[0]//dim)*dim,stride):\n",
    "                max=0\n",
    "                for h in range(dim):\n",
    "                    for l in range(dim):\n",
    "                        if img[x+l][y+h][rgb]>max:\n",
    "                            max=img[x+l][y+h][rgb]\n",
    "                newImg[((x-dim)//stride)+1][((y-dim)//stride)+1][rgb]=max\n",
    "    \n",
    "    return newImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c230e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pooling(img,dim=2,padding=None,stride=1):\n",
    "    if padding is not None:\n",
    "        img=imgPadding(img,padding)\n",
    "    \n",
    "    newDim=((img.shape[0]-dim)//stride)+1\n",
    "    newImg=np.zeros([newDim,newDim,3])\n",
    "    \n",
    "    for rgb in range(img.shape[2]):\n",
    "        for x in range(0,(img.shape[0]//dim)*dim,stride):\n",
    "            for y in range(0,(img.shape[0]//dim)*dim,stride):\n",
    "                somme=0\n",
    "                for h in range(dim):\n",
    "                    for l in range(dim):\n",
    "                        somme+=img[x+l][y+h][rgb]\n",
    "                newImg[((x-dim)//stride)+1][((y-dim)//stride)+1][rgb]=somme//dim*dim\n",
    "    \n",
    "    return newImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bce79b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(nb_classes):\n",
    "    model=nn.Sequential(\n",
    "        nn.Conv2d(1,16,kernel_size=3,padding=1), #(1,100,100) -> (16,100,100)\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2), #(16,100,100) -> ((100-2)//2)+1 = 49+1 = 50 donc -> (16,50,50)\n",
    "        nn.Conv2d(16,32,kernel_size=3,padding=1), #(16,50,50) -> (32,50,50)\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2), #(32,50,50) -> ((50-2)//2)+1 = 25 -> (32,25,25)\n",
    "        nn.Flatten(), #(32,25,25) -> (32*25*25) = (20000)\n",
    "        #nn.Dropout(0.3) #pour éviter l'overfitting\n",
    "        nn.Linear(20000,128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128,nb_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "502884af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_train(X_train,y_train,nb_epoch,labels,batch_size,model=None):\n",
    "    if model is None: #créé un model si on en donne pas\n",
    "        model=make_model(len(list(set(y_train))))\n",
    "    \n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #set le device to the GPU or CPU\n",
    "    model.to(device) #envoie le model au device\n",
    "\n",
    "    y_train_tensor=torch.tensor([labels[y] for y in y_train])\n",
    "\n",
    "    X_train_tensor=[imgProcess(img,withTorch=True) for img in X_train] #applique l'imgprocess en mode torch aux images train\n",
    "    X_train_tensor=torch.cat(X_train_tensor,dim=0) #stock toutes les images stockées dans X_train_tensor dans un conteneur tensor = créé le batch de taille len(X_train)\n",
    "    \n",
    "    dataset=TensorDataset(X_train_tensor,y_train_tensor) #assemble nos data pour créer le dataset tensor\n",
    "    dataloader=DataLoader(dataset,batch_size=batch_size,shuffle=True) #shuffle -> pour changer l'ordre des pairs img-label pour pas qu'on choppe des batchs uniquement du même label\n",
    "    #le dataloader va séparer le dataset de taille N en (N//batch_size)+1 si N%batch_size != 0 -> il y aura N//batch_size batchs complets et un batch plus petit avec les data restantes\n",
    "    #on peut rajouter le param drop_last=True si on veut supprimer le dernier batch -> +stabilité et certaines couches demandent un full batch (BatchNorm par ex)\n",
    "    #+ le batch_size est élevé + ce sera précis mais + ça consommera\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss() #fonction de coût/perte à minimiser -> crossentropy utilisée pour la classification multiclasse\n",
    "    #applique softmax à la prédiction (qui sont des scores) pour transformer les scores en probabilités puis compare les proba à la classe cible et renvoie une erreur.\n",
    "    #plus la probabilité de la bonne classe est faible, plus la perte sera grande\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #lr = learning rate -> plus c'est petit plus c'est progressif et donc plus il aura besoin d'apprentissage mais plus il sera précis\n",
    "    #Adam = Adaptive Moment Estimation -> optimiseur pour réduire la perte. Adam adapte le lr localement donc pas besoin de régler le lr très finement. Utilise le SGD (Stochastic Gradient Descent)\n",
    "    #SGD -> minimisation de la perte pour chaque exemple individuellement là ou le classique GD minimise la perte globale -> SGD plus bruité (moins stable) mais + rapide\n",
    "\n",
    "    model.train() #active le mode training\n",
    "    for epoch in range(nb_epoch): # 1 epoque = le moment où le modèle a vu tout le dataset donc une époque = tous les (N//batch_size)+1 batchs\n",
    "        # plus il y a d'epoch + le model va apprendre et réduire l'erreur mais attention à l'overfitting\n",
    "        #-> petit dataset(>1000) = 10 to 50 epochs -> moyen dataset (1000 to 100k) = 20 to 100 et grand dataset (>100k) -> 10 to 50\n",
    "        #SINON -> utiliser early stopping pour être précis qui stop quand la précision sur validation baisse ou n'augmente plus -> à coder soit même\n",
    "        total_loss=0.0\n",
    "        correct=0\n",
    "        total=0\n",
    "\n",
    "        for img,labels in dataloader:\n",
    "            img=img.to(device) #envoie les img au device\n",
    "            labels=labels.to(device) #envoie les labels au device, tout à besoin d'être sur le même device pour être traité\n",
    "\n",
    "            outputs=model(img) #prédiction des img (forward)\n",
    "            loss=criterion(outputs,labels) #calcul de la perte avec le criterion (ici crossentropy)\n",
    "\n",
    "            #rétropropagation (backward)\n",
    "            optimizer.zero_grad() #remet les gradients à 0\n",
    "            loss.backward()  #calcul les nouveaux gradients\n",
    "\n",
    "            optimizer.step() #mise à jour des poids\n",
    "\n",
    "            #partie statistiques (facultatif mais utile)\n",
    "            total_loss+=loss.item() #additionne la loss de chaque epoch\n",
    "            _,predicted=torch.max(outputs,1) #prend le score max de la dim 1 de output qui correspond à la classe et prend uniquement la classe associée à ce score max = les classes prédites\n",
    "            correct+=(predicted==labels).sum().item() #compte combien de ces preds sont correctes\n",
    "            total+=labels.size(0) #compte le nb d'img traitées dans cette epoch (labels.size(0)=32 ici vu que c'est le batch_size)\n",
    "            \n",
    "        acc=100*correct/total #bonnes prédictions sur l'ensemble de l'epoch en %\n",
    "        print(f\"Epoch : {epoch+1}/{nb_epoch}\\n Perte :{total_loss:.4f}\\n Précision : {acc:.2f}%\")\n",
    "    \n",
    "    print(\"Training terminé.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e7c90f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_evaluate(X_test,y_test,model,labels,batch_size):\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "        \n",
    "        model.eval() #active le mode evaluation\n",
    "\n",
    "        y_test_tensor=torch.tensor([labels[y] for y in y_test])\n",
    "\n",
    "        X_test_tensor=[imgProcess(img,withTorch=True) for img in X_test]\n",
    "        X_test_tensor=torch.cat(X_test_tensor,dim=0)\n",
    "    \n",
    "        test_dataset=TensorDataset(X_test_tensor,y_test_tensor)\n",
    "        testloader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "        correct=0\n",
    "        total=0\n",
    "\n",
    "        with torch.no_grad(): #pas de backward (juste forward = pred)\n",
    "            for img,labels in testloader:\n",
    "                  img=img.to(device)\n",
    "                  labels=labels.to(device)\n",
    "\n",
    "                  outputs=model(img)\n",
    "                  _,pred=torch.max(outputs,1)\n",
    "\n",
    "                  correct+=(pred==labels).sum().item()\n",
    "                  total+=labels.size(0)\n",
    "\n",
    "        print(f\"Précision sur le test : {correct/total *100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7e31e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_inf(img_path,model,labels):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    img=imgProcess(img_path,withTorch=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output=model(img)\n",
    "        _,pred=torch.max(output,1)\n",
    "    \n",
    "    return labels[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bfcaf8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid SOS parameters for sequential JPEG\n"
     ]
    }
   ],
   "source": [
    "#X_train,y_train,X_test,y_test=extract_data(\"Faces\",\"yes\")\n",
    "X_train,y_train=extract_data(\"nous/Train\")\n",
    "X_test,y_test=extract_data(\"nous/Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c31fedb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/5\n",
      " Perte :5.8773\n",
      " Précision : 65.00%\n",
      "Epoch : 2/5\n",
      " Perte :3.9596\n",
      " Précision : 85.00%\n",
      "Epoch : 3/5\n",
      " Perte :2.6721\n",
      " Précision : 85.00%\n",
      "Epoch : 4/5\n",
      " Perte :1.8927\n",
      " Précision : 95.00%\n",
      "Epoch : 5/5\n",
      " Perte :0.4024\n",
      " Précision : 100.00%\n",
      "Training terminé.\n"
     ]
    }
   ],
   "source": [
    "labels={label:i for i,label in enumerate(sorted(set(y_train)))} #list(set(y_train)) sort les val uniques en list et sorted les range dans l'ordre alphabétique \n",
    "model=CNN_train(X_train=X_train,y_train=y_train,nb_epoch=5,labels=labels,batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "16a314bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur le test : 86.67%\n"
     ]
    }
   ],
   "source": [
    "CNN_evaluate(X_test=X_test,y_test=y_test,model=model,labels=labels,batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2822a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convertion de l'img\n",
      "Augustin\n"
     ]
    }
   ],
   "source": [
    "id2label = {v: k for k, v in labels.items()}\n",
    "print(CNN_inf(\"test.jpg\",model,id2label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
