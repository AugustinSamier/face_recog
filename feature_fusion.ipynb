{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894072b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from math import sqrt\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7162b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(path,create_test=None):\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "\n",
    "    file=os.listdir(path)\n",
    "\n",
    "    for entity in file:\n",
    "        try:\n",
    "            entityPath=os.listdir(f\"{path}/{entity}\")\n",
    "            for i,data in enumerate(entityPath):\n",
    "                try:\n",
    "                    current_img=cv2.imread(f\"{path}/{entity}/{data}\")\n",
    "                    if current_img is not None:\n",
    "                        if (create_test is not None and ((len(entityPath)>1) and (i==0))):\n",
    "                            X_test.append(current_img)\n",
    "                            y_test.append(entity)\n",
    "                        else:\n",
    "                            X_train.append(current_img)\n",
    "                            y_train.append(entity)\n",
    "                    else:\n",
    "                        print(f\"{path}/{entity}/{data} is None type\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur avec {path}/{entity}/{data} : {e}\")\n",
    "        except Exception as ex:\n",
    "            print(f\"Erreur avec {path}/{entity} : {ex}\")\n",
    "    \n",
    "    print(f\"Number of training sample : {len(X_train)}\\n\")\n",
    "    if create_test is not None:\n",
    "        print(f\"Number of test sample : {len(X_test)}\\n\")\n",
    "        return X_train,y_train,X_test,y_test\n",
    "    else:\n",
    "        return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test=transforms.Compose([\n",
    "    transforms.ToPILImage(), #transforme en format PIL \n",
    "    transforms.ToTensor() #reconvertit l'img en format tensor\n",
    "])\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToPILImage(), #transforme en format PIL\n",
    "    transforms.RandomHorizontalFlip(), #0.5 de proba d'inverser la gauche et la droite de l'img pour rendre le modèle invariant à la symétrie\n",
    "    transforms.RandomRotation(15), #applique rota random entre -10° et +10° \n",
    "    transforms.ColorJitter(brightness=0.3,contrast=0.3,saturation=0.2,hue=0.02), #altère aléatoirement la luminosité et le contraste de l'image\n",
    "    transforms.ToTensor() #reconvertit l'img en format tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9315f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgProcess(img,withTorch=None,tr=True):\n",
    "    if not isinstance(img,np.ndarray):\n",
    "        print(\"convertion de l'img\")\n",
    "        img=cv2.imread(img)\n",
    "\n",
    "    img=cv2.resize(img,(100,100))\n",
    "    if withTorch is None:\n",
    "        img=img.flatten()\n",
    "    else:\n",
    "        if tr is not None:\n",
    "            img=transform(img)\n",
    "        else:\n",
    "            img=transform_test(img)\n",
    "        img=img.unsqueeze(0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_and_eyes(img):\n",
    "    if not isinstance(img,np.ndarray):\n",
    "        img=cv2.imread(img)\n",
    "\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(60,60)\n",
    "    )\n",
    "\n",
    "    if len(faces)==0:\n",
    "        return [],[]\n",
    "    \n",
    "    x,y,w,h=faces[0]\n",
    "    face=img[y:y+h,x:x+w]\n",
    "    eyes=eye_cascade.detectMultiScale(cv2.cvtColor(face,cv2.COLOR_BGR2GRAY))\n",
    "    if len(eyes)==2:\n",
    "        if eyes[0][0]<eyes[1][0]:\n",
    "            x2=eyes[0][0]\n",
    "            w2=eyes[1][0]+eyes[1][2]-x2\n",
    "        else:\n",
    "            x2=eyes[1][0]\n",
    "            w2=eyes[0][0]+eyes[0][2]-x2\n",
    "        if eyes[0][1]<eyes[1][1]:\n",
    "            y2=eyes[0][1]\n",
    "            h2=eyes[1][1]+eyes[1][3]-y2\n",
    "        else:\n",
    "            y2=eyes[1][1]\n",
    "            h2=eyes[0][1]+eyes[0][3]-y2\n",
    "        imgEyes=face[y2:y2+h2,x2:x2+w2]\n",
    "        return face,imgEyes\n",
    "    else:\n",
    "        return face,[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a295f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createData(X,y):\n",
    "    x_face=[]\n",
    "    y_face=[]\n",
    "    x_eyes=[]\n",
    "    y_eyes=[]\n",
    "    for i,x in enumerate(X):\n",
    "        face,eyes=extract_face_and_eyes(x)\n",
    "        if len(face)!=0:\n",
    "            x_face.append(face)\n",
    "            y_face.append(y[i])\n",
    "        if len(eyes)!=0:\n",
    "            x_eyes.append(eyes)\n",
    "            y_eyes.append(y[i])\n",
    "    return x_face,y_face,x_eyes,y_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_face_and_eyes_models(nb_classes):\n",
    "    face_model=nn.Sequential(\n",
    "\n",
    "    )\n",
    "\n",
    "    eyes_model=nn.Sequential(\n",
    "\n",
    "    )\n",
    "\n",
    "    final_classifier=nn.Sequential(\n",
    "        nn.Linear(),\n",
    "        nn.ReLU(),\n",
    "        #nn.Dropout(),\n",
    "        nn.Linear(,nb_classes)\n",
    "    )\n",
    "\n",
    "    return face_model,eyes_model,final_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_models(face_model,eyes_model,face_img,eyes_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72564b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_train(X_train,y_train,nb_epoch,labels,batch_size,models=None,patience=5,val_split=None):\n",
    "    if models is None:\n",
    "        face_model,eyes_model,final_classifier=make_face_and_eyes_models(len(list(set(y_train))))\n",
    "    else:\n",
    "        face_model,eyes_model,final_classifier=models\n",
    "\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    face_model.to(device)\n",
    "    eyes_model.to(device)\n",
    "    final_classifier.to(device)\n",
    "\n",
    "    if val_split is not None:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train,random_state=1)\n",
    "        val_dataset = list(zip(X_val, [labels[y] for y in y_val]))\n",
    "        val_loader = DataLoader(val_dataset, batch_size=5, shuffle=False, collate_fn=lambda x: x)\n",
    "        best_val_acc = 0\n",
    "        wait = 0\n",
    "\n",
    "    y_train_tensor=torch.tensor([labels[y] for y in y_train])\n",
    "\n",
    "    dataset=list(zip(X_train,y_train_tensor))\n",
    "    dataloader=DataLoader(dataset,batch_size=batch_size,shuffle=True,collate_fn=lambda x: x)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    tabTrain=[]\n",
    "    tabVal=[]\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(nb_epoch):\n",
    "        total_loss=0.0\n",
    "        correct=0\n",
    "        total=0\n",
    "        for batch in dataloader:\n",
    "            X_raw,labels_batch=zip(*batch)\n",
    "            img=[imgProcess(image,withTorch=True) for image in X_raw]\n",
    "            img=torch.cat(img,dim=0)\n",
    "            img=img.to(device)\n",
    "            labelsT=torch.tensor(labels_batch).to(device)\n",
    "\n",
    "            outputs=model(img)\n",
    "            loss=criterion(outputs,labelsT)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss+=loss.item()\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            correct+=(predicted==labelsT).sum().item()\n",
    "            total+=labelsT.size(0)\n",
    "            \n",
    "        acc=100*correct/total\n",
    "        tabTrain.append(acc)\n",
    "        print(f\"\\nEpoch : {epoch+1}/{nb_epoch}\\n Perte :{total_loss:.4f}\\n Précision : {acc:.2f}%\")\n",
    "        if val_split is not None:\n",
    "            true,false,tot=CNN_evaluate(model=model,labels=labels,loader=val_loader,device=device)\n",
    "            val_acc=sum(true.values())/sum(tot.values())\n",
    "            tabVal.append(100*val_acc)\n",
    "            if val_acc>best_val_acc:\n",
    "                best_val_acc=val_acc\n",
    "                wait=0\n",
    "                best_model=copy.deepcopy(model.state_dict())\n",
    "            else:\n",
    "                wait+=1\n",
    "                if wait>=patience:\n",
    "                    print(\"Early stopping activated\")\n",
    "                    break\n",
    "            print(f\"\\n Val accuracy : {val_acc*100:.2f}%\\n Série sans amélioration : {wait}\")\n",
    "            model.load_state_dict(best_model)\n",
    "        \n",
    "    absc=list(range(len(tabTrain)))\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(absc,tabTrain,label=\"Training\",marker=\"o\")\n",
    "    if val_split is not None:\n",
    "        plt.plot(absc,tabVal,label=\"Validation\",marker=\"s\")\n",
    "    plt.xlim(1,len(tabTrain))\n",
    "    plt.ylim(0,100)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    print(\"Training terminé.\")\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=extract_data(\"DataFaces\")\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_train,y_train,test_size=0.2,random_state=1,stratify=y_train)\n",
    "X_train_faces,y_train_faces,X_train_eyes,y_train_eyes=createData(X_train,y_train)\n",
    "X_test_faces,y_test_faces,X_test_eyes,y_test_eyes=createData(X_test,y_test)\n",
    "labels={label:i for i,label in enumerate(sorted(set(y_train)))} #list(set(y_train)) sort les val uniques en list et sorted les range dans l'ordre alphabétique\n",
    "print(f\"Face train samples : {len(X_train_faces)}.\\nEyes train samples : {len(X_train_eyes)}.\\nFace test samples : {len(X_test_faces)}.\\nEyes test samples : {len(X_test_eyes)}.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
