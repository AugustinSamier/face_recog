{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894072b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "from math import sqrt\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7162b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(path,create_test=None):\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "\n",
    "    file=os.listdir(path)\n",
    "\n",
    "    for entity in file:\n",
    "        try:\n",
    "            entityPath=os.listdir(f\"{path}/{entity}\")\n",
    "            for i,data in enumerate(entityPath):\n",
    "                try:\n",
    "                    current_img=cv2.imread(f\"{path}/{entity}/{data}\")\n",
    "                    if current_img is not None:\n",
    "                        if (create_test is not None and ((len(entityPath)>1) and (i==0))):\n",
    "                            X_test.append(current_img)\n",
    "                            y_test.append(entity)\n",
    "                        else:\n",
    "                            X_train.append(current_img)\n",
    "                            y_train.append(entity)\n",
    "                    else:\n",
    "                        print(f\"{path}/{entity}/{data} is None type\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur avec {path}/{entity}/{data} : {e}\")\n",
    "        except Exception as ex:\n",
    "            print(f\"Erreur avec {path}/{entity} : {ex}\")\n",
    "    \n",
    "    print(f\"Number of training sample : {len(X_train)}\\n\")\n",
    "    if create_test is not None:\n",
    "        print(f\"Number of test sample : {len(X_test)}\\n\")\n",
    "        return X_train,y_train,X_test,y_test\n",
    "    else:\n",
    "        return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e57c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_face_test=transforms.Compose([\n",
    "    transforms.ToPILImage(), #transforme en format PIL\n",
    "    transforms.Resize((100,100)),\n",
    "    transforms.ToTensor() #reconvertit l'img en format tensor\n",
    "])\n",
    "\n",
    "transform_face=transforms.Compose([\n",
    "    transforms.ToPILImage(), #transforme en format PIL\n",
    "    transforms.Resize((100,100)),\n",
    "    transforms.RandomHorizontalFlip(), #0.5 de proba d'inverser la gauche et la droite de l'img pour rendre le modèle invariant à la symétrie\n",
    "    transforms.RandomRotation(15), #applique rota random entre -10° et +10° \n",
    "    transforms.ColorJitter(brightness=0.3,contrast=0.3,saturation=0.2,hue=0.02), #altère aléatoirement la luminosité et le contraste de l'image\n",
    "    transforms.ToTensor() #reconvertit l'img en format tensor\n",
    "])\n",
    "\n",
    "transform_eyes=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((50,50)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_eyes_test=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((50,50)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b2a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_and_eyes(img):\n",
    "    if not isinstance(img,np.ndarray):\n",
    "        img=cv2.imread(img)\n",
    "\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(60,60)\n",
    "    )\n",
    "\n",
    "    if len(faces)==0:\n",
    "        return [],[]\n",
    "    \n",
    "    x,y,w,h=faces[0]\n",
    "    face=img[y:y+h,x:x+w]\n",
    "    eyes=eye_cascade.detectMultiScale(cv2.cvtColor(face,cv2.COLOR_BGR2GRAY))\n",
    "    if len(eyes)==2:\n",
    "        if eyes[0][0]<eyes[1][0]:\n",
    "            x2=eyes[0][0]\n",
    "            w2=eyes[1][0]+eyes[1][2]-x2\n",
    "        else:\n",
    "            x2=eyes[1][0]\n",
    "            w2=eyes[0][0]+eyes[0][2]-x2\n",
    "        if eyes[0][1]<eyes[1][1]:\n",
    "            y2=eyes[0][1]\n",
    "            h2=eyes[1][1]+eyes[1][3]-y2\n",
    "        else:\n",
    "            y2=eyes[1][1]\n",
    "            h2=eyes[0][1]+eyes[0][3]-y2\n",
    "        imgEyes=face[y2:y2+h2,x2:x2+w2]\n",
    "        return face,imgEyes\n",
    "    else:\n",
    "        return face,[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a295f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createData(X):\n",
    "    X_face=[]\n",
    "    X_eyes=[]\n",
    "    for i,x in enumerate(X):\n",
    "        face,eyes=extract_face_and_eyes(x)\n",
    "        if len(face)!=0:\n",
    "            X_face.append(face)\n",
    "        else:\n",
    "            X_face.append(np.zeros((100, 100, 3), dtype=np.uint8))\n",
    "        if len(eyes)!=0:\n",
    "            X_eyes.append(eyes)\n",
    "        else:\n",
    "            X_eyes.append(np.zeros((50, 50, 3), dtype=np.uint8))\n",
    "    return X_face,X_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72564b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceEyesDataset(Dataset):\n",
    "    def __init__(self, X, y, labels, transform_face, transform_eyes):\n",
    "        self.X = X  # Liste des chemins ou images\n",
    "        self.y = [labels[label] for label in y]  # Labels convertis en indices\n",
    "        self.transform_face = transform_face\n",
    "        self.transform_eyes = transform_eyes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.X[idx]\n",
    "\n",
    "        if not isinstance(img, np.ndarray):\n",
    "            img = cv2.imread(img)\n",
    "\n",
    "        face, eyes = extract_face_and_eyes(img)\n",
    "\n",
    "        if not isinstance(face, np.ndarray) or face.size == 0:\n",
    "            face = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "        if not isinstance(eyes, np.ndarray) or eyes.size == 0:\n",
    "            eyes = np.zeros((50, 50, 3), dtype=np.uint8)\n",
    "\n",
    "        face = self.transform_face(face)\n",
    "        eyes = self.transform_eyes(eyes)\n",
    "\n",
    "        label = self.y[idx]\n",
    "        return face, eyes, label\n",
    "\n",
    "def fusion_train(X_train,y_train,nb_epoch,labels,batch_size,models=None,patience=5,val_split=False):\n",
    "    nb_classes=len(list(set(y_train)))\n",
    "    if not models:\n",
    "        facemodel,eyesmodel,fusionModel=feature_fusionModel(nb_classes)\n",
    "    else:\n",
    "        fusionModel,facemodel,eyesmodel=models\n",
    "    \n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    fusionModel.to(device)\n",
    "    facemodel.to(device)\n",
    "    eyesmodel.to(device)\n",
    "\n",
    "    if val_split:\n",
    "        X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.2,random_state=1,stratify=y_train)\n",
    "        val_dataset=FaceEyesDataset(X_val,y_val,labels,transform_face=transform_face_test,transform_eyes=transform_eyes_test)\n",
    "        val_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=False)\n",
    "        best_val_acc=0\n",
    "        wait=0\n",
    "\n",
    "    train_dataset=FaceEyesDataset(X_train,y_train,labels,transform_face=transform_face,transform_eyes=transform_eyes)\n",
    "    train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    criterion=torch.nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.Adam(list(facemodel.parameters())+list(eyesmodel.parameters())+list(fusionModel.parameters()), lr=0.001)\n",
    "    #on veut optimiser les poids des trois modèles en même temps\n",
    "    tabTrain=[]\n",
    "    tabVal=[]\n",
    "    for epoch in range(nb_epoch):\n",
    "        fusionModel.train()\n",
    "        facemodel.train()\n",
    "        eyesmodel.train()\n",
    "\n",
    "        total_loss=0.0\n",
    "        correct=0\n",
    "        total=0\n",
    "\n",
    "        for face_batch,eyes_batch,y_batch in train_loader:\n",
    "            face_batch=face_batch.to(device)\n",
    "            eyes_batch=eyes_batch.to(device)\n",
    "            y_batch=y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            featuresFaces=facemodel(face_batch)\n",
    "            featuresEyes=eyesmodel(eyes_batch)\n",
    "            featuresFusion=torch.cat((featuresFaces,featuresEyes),dim=1)\n",
    "            outputs=fusionModel(featuresFusion)\n",
    "\n",
    "            loss=criterion(outputs,y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss+=loss.item()\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            correct+=(predicted==y_batch).sum().item()\n",
    "            total+=y_batch.size(0)\n",
    "        \n",
    "        acc=100*correct/total\n",
    "        tabTrain.append(acc)\n",
    "        print(f\"\\nEpoch : {epoch+1}/{nb_epoch}\\n Perte :{total_loss:.4f}\\n Précision : {acc:.2f}%\")\n",
    "\n",
    "        if val_split:\n",
    "            true,false,tot=fusionEvaluate((facemodel,eyesmodel,fusionModel),val_loader,labels)\n",
    "            val_acc=sum(true.values())/sum(tot.values())\n",
    "            tabVal.append(100*val_acc)\n",
    "            if val_acc>best_val_acc:\n",
    "                best_val_acc=val_acc #si l'acc de la val est meilleure on l'assigne et on reset le timer \n",
    "                wait=0\n",
    "                best_model_faces=copy.deepcopy(facemodel.state_dict())\n",
    "                best_model_eyes=copy.deepcopy(eyesmodel.state_dict())\n",
    "                best_model_fusion=copy.deepcopy(fusionModel.state_dict())\n",
    "            else:\n",
    "                if wait>=patience: #on attend le nombre d'epoch max sans amélioration\n",
    "                    print(\"Early stopping activated\")\n",
    "                    break\n",
    "                wait+=1\n",
    "            print(f\"\\n Val accuracy : {val_acc*100:.2f}%\\n Série sans amélioration : {wait}\")\n",
    "    facemodel.load_state_dict(best_model_faces)\n",
    "    eyesmodel.load_state_dict(best_model_eyes)\n",
    "    fusionModel.load_state_dict(best_model_fusion)\n",
    "        \n",
    "    absc=list(range(len(tabTrain)))\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(absc,tabTrain,label=\"Training\",marker=\"o\")\n",
    "    if val_split:\n",
    "        plt.plot(absc,tabVal,label=\"Validation\",marker=\"s\")\n",
    "    plt.xlim(1,len(tabTrain))\n",
    "    plt.ylim(0,100)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    print(\"Training terminé.\")\n",
    "    plt.show()\n",
    "    return facemodel,eyesmodel,fusionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201b5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionEvaluate(models,loader,labels,graph=False):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    facemodel,eyesmodel,fusionmodel=models\n",
    "    facemodel.to(device)\n",
    "    facemodel.eval()\n",
    "    eyesmodel.to(device)\n",
    "    eyesmodel.eval()\n",
    "    fusionmodel.to(device)\n",
    "    fusionmodel.eval()\n",
    "\n",
    "    labelF=defaultdict(int)\n",
    "    labelC=defaultdict(int)\n",
    "    labelT=defaultdict(int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for faces_batch,eyes_batch,y_batch in loader:\n",
    "            faces_batch=faces_batch.to(device)\n",
    "            eyes_batch=eyes_batch.to(device)\n",
    "            y_batch=y_batch.to(device)\n",
    "\n",
    "            featuresFaces=facemodel(faces_batch)\n",
    "            featuresEyes=eyesmodel(eyes_batch)\n",
    "            featuresFusion=torch.cat((featuresFaces,featuresEyes),dim=1)\n",
    "            outputs=fusionmodel(featuresFusion)\n",
    "\n",
    "            _,pred=torch.max(outputs,1)\n",
    "            for i in range(len(y_batch)):\n",
    "                label=y_batch[i].item()\n",
    "                pred[i]=pred[i].item()\n",
    "\n",
    "                if pred[i]==label:\n",
    "                    labelC[label]+=1\n",
    "                else:\n",
    "                    labelF[label]+=1\n",
    "                labelT[label]+=1\n",
    "\n",
    "    if graph:\n",
    "        print(f\"Total precision : {sum(labelC.values())/sum(labelT.values())*100:.2f}%\")\n",
    "        precisions={}\n",
    "        for label in labelT:\n",
    "            tot=labelT[label]\n",
    "            correct=labelC.get(label,0)\n",
    "            precisions[label]=correct/tot if tot>0 else 0\n",
    "        prec_sorted=sorted(precisions.items(),key=lambda x: x[1])\n",
    "        labels_ids,values= zip(*prec_sorted)\n",
    "\n",
    "        id2label = {v: k for k, v in labels.items()}\n",
    "        class_names=[id2label[i] for i in labels_ids]\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.bar(class_names, values, color='skyblue')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel(\"Précision par classe\")\n",
    "        plt.title(\"Performance du modèle par classe\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return labelC,labelF,labelT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba4c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_fusionModel(nb_classes):\n",
    "    face_model=nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=3, padding=1),   # (1,100,100) -> (16,100,100)\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),                           # (16,50,50)\n",
    "\n",
    "        nn.Conv2d(16, 32, kernel_size=3, padding=1),  # (32,50,50)\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),                           # (32,25,25)\n",
    "\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1),  # (64,25,25)\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),                           # (64,12,12)\n",
    "\n",
    "        nn.Flatten(),                                 # 64*12*12 = 9216\n",
    "        nn.Linear(9216, 512),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    eyes_model=nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=3, padding=1),   # (1,50,50) -> (16,50,50)\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),                           # (16,25,25)\n",
    "\n",
    "        nn.Conv2d(16, 32, kernel_size=3, padding=1),  # (32,25,25)\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),                           # (32,12,12)\n",
    "\n",
    "        nn.Flatten(),                                 # 32*12*12 = 4608\n",
    "        nn.Linear(4608, 256),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    final_classifier=nn.Sequential(\n",
    "        nn.Linear(768, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),  # Dropout pour éviter l'overfitting\n",
    "\n",
    "        nn.Linear(256, nb_classes)\n",
    "    )\n",
    "\n",
    "    return face_model,eyes_model,final_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a846921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sample : 17534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train=extract_data(\"DataFaces\")\n",
    "labels={label:i for i,label in enumerate(sorted(set(y_train)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07623350",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_train,y_train,test_size=0.2,random_state=1,stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac68eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 1/150\n",
      " Perte :1628.0634\n",
      " Précision : 1.20%\n",
      "\n",
      " Val accuracy : 1.85%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 2/150\n",
      " Perte :1612.2562\n",
      " Précision : 1.54%\n",
      "\n",
      " Val accuracy : 1.89%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 3/150\n",
      " Perte :1581.6662\n",
      " Précision : 2.34%\n",
      "\n",
      " Val accuracy : 2.53%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 4/150\n",
      " Perte :1556.1448\n",
      " Précision : 2.88%\n",
      "\n",
      " Val accuracy : 3.42%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 5/150\n",
      " Perte :1529.1080\n",
      " Précision : 3.80%\n",
      "\n",
      " Val accuracy : 4.85%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 6/150\n",
      " Perte :1496.1167\n",
      " Précision : 5.20%\n",
      "\n",
      " Val accuracy : 5.38%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 7/150\n",
      " Perte :1463.5623\n",
      " Précision : 6.33%\n",
      "\n",
      " Val accuracy : 7.56%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 8/150\n",
      " Perte :1431.4904\n",
      " Précision : 7.82%\n",
      "\n",
      " Val accuracy : 9.19%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 9/150\n",
      " Perte :1400.5183\n",
      " Précision : 9.38%\n",
      "\n",
      " Val accuracy : 9.48%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 10/150\n",
      " Perte :1369.1638\n",
      " Précision : 11.25%\n",
      "\n",
      " Val accuracy : 10.19%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 11/150\n",
      " Perte :1339.9835\n",
      " Précision : 12.62%\n",
      "\n",
      " Val accuracy : 10.83%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 12/150\n",
      " Perte :1315.2047\n",
      " Précision : 13.83%\n",
      "\n",
      " Val accuracy : 11.87%\n",
      " Série sans amélioration : 0\n",
      "\n",
      "Epoch : 13/150\n",
      " Perte :1287.8188\n",
      " Précision : 15.47%\n",
      "\n",
      " Val accuracy : 11.97%\n",
      " Série sans amélioration : 0\n"
     ]
    }
   ],
   "source": [
    "facemodel,eyesmodel,fusionmodel=fusion_train(X_train,y_train,nb_epoch=150,labels=labels,batch_size=32,patience=20,val_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "facestest,eyestest=extract_face_and_eyes(X_test)\n",
    "labelC,labelF,labelT=fusionEvaluate((facemodel,eyesmodel,fusionmodel),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionPipeline(X,y):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
