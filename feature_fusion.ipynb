{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894072b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from math import sqrt\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7162b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(path,create_test=None):\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "\n",
    "    file=os.listdir(path)\n",
    "\n",
    "    for entity in file:\n",
    "        try:\n",
    "            entityPath=os.listdir(f\"{path}/{entity}\")\n",
    "            for i,data in enumerate(entityPath):\n",
    "                try:\n",
    "                    current_img=cv2.imread(f\"{path}/{entity}/{data}\")\n",
    "                    if current_img is not None:\n",
    "                        if (create_test is not None and ((len(entityPath)>1) and (i==0))):\n",
    "                            X_test.append(current_img)\n",
    "                            y_test.append(entity)\n",
    "                        else:\n",
    "                            X_train.append(current_img)\n",
    "                            y_train.append(entity)\n",
    "                    else:\n",
    "                        print(f\"{path}/{entity}/{data} is None type\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur avec {path}/{entity}/{data} : {e}\")\n",
    "        except Exception as ex:\n",
    "            print(f\"Erreur avec {path}/{entity} : {ex}\")\n",
    "    \n",
    "    print(f\"Number of training sample : {len(X_train)}\\n\")\n",
    "    if create_test is not None:\n",
    "        print(f\"Number of test sample : {len(X_test)}\\n\")\n",
    "        return X_train,y_train,X_test,y_test\n",
    "    else:\n",
    "        return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e57c1a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transform_face_test\u001b[38;5;241m=\u001b[39m\u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      2\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToPILImage(), \u001b[38;5;66;03m#transforme en format PIL\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m)),\n\u001b[1;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor() \u001b[38;5;66;03m#reconvertit l'img en format tensor\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      7\u001b[0m transform_face\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      8\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToPILImage(), \u001b[38;5;66;03m#transforme en format PIL\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor() \u001b[38;5;66;03m#reconvertit l'img en format tensor\u001b[39;00m\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     16\u001b[0m transform_eyes\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     17\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToPILImage(),\n\u001b[1;32m     18\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m50\u001b[39m)),\n\u001b[1;32m     19\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor()\n\u001b[1;32m     20\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "transform_face_test=transforms.Compose([\n",
    "    transforms.ToPILImage(), #transforme en format PIL\n",
    "    transforms.Resize((100,100)),\n",
    "    transforms.ToTensor() #reconvertit l'img en format tensor\n",
    "])\n",
    "\n",
    "transform_face=transforms.Compose([\n",
    "    transforms.ToPILImage(), #transforme en format PIL\n",
    "    transforms.Resize((100,100)),\n",
    "    transforms.RandomHorizontalFlip(), #0.5 de proba d'inverser la gauche et la droite de l'img pour rendre le modèle invariant à la symétrie\n",
    "    transforms.RandomRotation(15), #applique rota random entre -10° et +10° \n",
    "    transforms.ColorJitter(brightness=0.3,contrast=0.3,saturation=0.2,hue=0.02), #altère aléatoirement la luminosité et le contraste de l'image\n",
    "    transforms.ToTensor() #reconvertit l'img en format tensor\n",
    "])\n",
    "\n",
    "transform_eyes=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((50,50)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_eyes_test=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((50,50)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_and_eyes(img):\n",
    "    if not isinstance(img,np.ndarray):\n",
    "        img=cv2.imread(img)\n",
    "\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(60,60)\n",
    "    )\n",
    "\n",
    "    if len(faces)==0:\n",
    "        return [],[]\n",
    "    \n",
    "    x,y,w,h=faces[0]\n",
    "    face=img[y:y+h,x:x+w]\n",
    "    eyes=eye_cascade.detectMultiScale(cv2.cvtColor(face,cv2.COLOR_BGR2GRAY))\n",
    "    if len(eyes)==2:\n",
    "        if eyes[0][0]<eyes[1][0]:\n",
    "            x2=eyes[0][0]\n",
    "            w2=eyes[1][0]+eyes[1][2]-x2\n",
    "        else:\n",
    "            x2=eyes[1][0]\n",
    "            w2=eyes[0][0]+eyes[0][2]-x2\n",
    "        if eyes[0][1]<eyes[1][1]:\n",
    "            y2=eyes[0][1]\n",
    "            h2=eyes[1][1]+eyes[1][3]-y2\n",
    "        else:\n",
    "            y2=eyes[1][1]\n",
    "            h2=eyes[0][1]+eyes[0][3]-y2\n",
    "        imgEyes=face[y2:y2+h2,x2:x2+w2]\n",
    "        return face,imgEyes\n",
    "    else:\n",
    "        return face,[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a295f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createData(X):\n",
    "    X_face=[]\n",
    "    X_eyes=[]\n",
    "    for i,x in enumerate(X):\n",
    "        face,eyes=extract_face_and_eyes(x)\n",
    "        X_face.append(face)\n",
    "        if len(eyes)!=0:\n",
    "            X_eyes.append(eyes)\n",
    "        else:\n",
    "            X_eyes.append(None)\n",
    "    return X_face,X_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72564b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceEyesDataset(Dataset):\n",
    "    def __init__(self,faces,eyes,labels):\n",
    "        self.faces=faces\n",
    "        self.eyes=eyes\n",
    "        self.labels=labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.faces)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.faces[idx],self.eyes[idx],self.labels[idx]\n",
    "\n",
    "def CNN_train(X_train,y_train,nb_epoch,labels,batch_size,models=None,patience=5,val_split=False):\n",
    "    nb_classes=len(list(set(y_train)))\n",
    "    if not models:\n",
    "        fusionModel=feature_fusionModel(nb_classes)\n",
    "        facemodel=faceCNN(nb_classes)\n",
    "        eyesmodel=eyesCNN(nb_classes)\n",
    "    else:\n",
    "        fusionModel,facemodel,eyesmodel=models\n",
    "    \n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    fusionModel.to(device)\n",
    "    facemodel.to(device)\n",
    "    eyesmodel.to(device)\n",
    "\n",
    "    X_face,X_eyes=createData(X_train)\n",
    "    faceslist=([transform_face(x) for x in X_face])\n",
    "    ytorchlist=([labels[y] for y in y_train])\n",
    "    eyeslist=[]\n",
    "    for eye in X_eyes:\n",
    "        if eye:\n",
    "            eyeslist.append(transform_eyes(eye))\n",
    "        else:\n",
    "            eyeslist.append(torch.zeros((1,50,50)))\n",
    "\n",
    "    if val_split:\n",
    "        faceslist,faces_val,eyeslist,eyes_val,ytorchlist,y_val=train_test_split(faceslist,eyeslist,ytorchlist,test_size=0.2,random_state=1,stratify=ytorchlist)\n",
    "        faces_val=torch.stack(faces_val)\n",
    "        eyes_val=torch.stack(eyes_val)\n",
    "        y_val=torch.tensor(y_val,dtype=torch.long)\n",
    "        val_dataset=FaceEyesDataset(faces_val,eyes_val,y_val)\n",
    "        val_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    faces=torch.stack(faceslist)\n",
    "    eyes=torch.stack(eyeslist)\n",
    "    ytorch=torch.tensor(ytorchlist,dtype=torch.long)\n",
    "\n",
    "    train_dataset=FaceEyesDataset(faces,eyes,ytorch)\n",
    "    train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    criterion=torch.nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.Adam(list(facemodel.parameters())+list(eyesmodel.parameters())+list(fusionModel.parameters()), lr=0.001)\n",
    "    #on veut optimiser les poids des trois modèles en même temps\n",
    "    tabTrain=[]\n",
    "    tabVal=[]\n",
    "    for epoch in range(nb_epoch):\n",
    "        fusionModel.train()\n",
    "        facemodel.train()\n",
    "        eyesmodel.train()\n",
    "\n",
    "        total_loss=0.0\n",
    "        correct=0\n",
    "        total=0\n",
    "\n",
    "        for face_batch,eyes_batch,y_batch in train_loader:\n",
    "            face_batch=face_batch.to(device)\n",
    "            eye_batch=eye_batch.to(device)\n",
    "            y_batch=y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            featuresFaces=facemodel(face_batch)\n",
    "            featuresEyes=eyesmodel(eyes_batch)\n",
    "            featuresFusion=torch.cat((featuresFaces,featuresEyes),dim=1)\n",
    "            outputs=fusionModel(featuresFusion)\n",
    "\n",
    "            loss=criterion(outputs,y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss+=loss.item()\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            correct+=(predicted==y_batch).sum().item()\n",
    "            total+=y_batch.size(0)\n",
    "        \n",
    "        acc=100*correct/total\n",
    "        tabTrain.append(acc)\n",
    "        print(f\"\\nEpoch : {epoch+1}/{nb_epoch}\\n Perte :{total_loss:.4f}\\n Précision : {acc:.2f}%\")\n",
    "\n",
    "        if val_split:\n",
    "            true,false,tot=fusionEvaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionEvaluate(models,loader):\n",
    "    if device is None:\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    facemodel,eyesmodel,fusionmodel=models\n",
    "    facemodel.to(device)\n",
    "    facemodel.eval()\n",
    "    eyesmodel.to(device)\n",
    "    eyesmodel.eval()\n",
    "    fusionmodel.to(device)\n",
    "    fusionmodel.eval()\n",
    "\n",
    "    labelF=defaultdict(int)\n",
    "    labelC=defaultdict(int)\n",
    "    labelT=defaultdict(int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for faces_batch,eyes_batch,y_batch in loader:\n",
    "            faces_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4c7f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1440684627.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    nn.Linear(,nb_classes)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def feature_fusionModel(nb_classes):\n",
    "    face_model=nn.Sequential(\n",
    "\n",
    "    )\n",
    "\n",
    "    eyes_model=nn.Sequential(\n",
    "\n",
    "    )\n",
    "\n",
    "    final_classifier=nn.Sequential(\n",
    "        nn.Linear(),\n",
    "        nn.ReLU(),\n",
    "        #nn.Dropout(),\n",
    "        nn.Linear(,nb_classes)\n",
    "    )\n",
    "\n",
    "    return face_model,eyes_model,final_classifier\n",
    "\n",
    "def faceCNN(nb_classes):\n",
    "    facemodel=nn.Sequential(\n",
    "\n",
    "    )\n",
    "    return facemodel\n",
    "\n",
    "def eyesCNN(nb_classes):\n",
    "    eyesmodel=nn.Sequential(\n",
    "\n",
    "    )\n",
    "    return eyesmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=extract_data(\"DataFaces\")\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_train,y_train,test_size=0.2,random_state=1,stratify=y_train)\n",
    "X_train_faces,y_train_faces,X_train_eyes,y_train_eyes=createData(X_train,y_train)\n",
    "X_test_faces,y_test_faces,X_test_eyes,y_test_eyes=createData(X_test,y_test)\n",
    "labels={label:i for i,label in enumerate(sorted(set(y_train)))} #list(set(y_train)) sort les val uniques en list et sorted les range dans l'ordre alphabétique\n",
    "print(f\"Face train samples : {len(X_train_faces)}.\\nEyes train samples : {len(X_train_eyes)}.\\nFace test samples : {len(X_test_faces)}.\\nEyes test samples : {len(X_test_eyes)}.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
